# Image Annotation Layers
> All of these input formats have the same formatting as our responses, so passing one Scale tasks' data to another Scale task is really easy.

```js
var scaleapi = require('scaleapi');

var client = scaleapi.ScaleClient('{{ApiKey}}');

// This example uses express with body-parser
app.post('/polygon_task_callback_handler', function(req, res) {
  // Validate callback auth key
  ...

  var polygons = req.body.response.annotations;
  var attachment = req.body.task.params.attachment;

  client.createAnnotationTask({
    'callback_url': 'http://www.example.com/annotation_task_callback_handler',
    'instruction': 'Draw a box around each **car** and **pedestrian**',
    'attachment_type': 'image',
    'attachment': attachment,
    'objects_to_annotate': ['car', 'pedestrian'],
    'with_labels': true,
    'min_width': '30',
    'min_height': '30',
    'layers': {
      'polygons': polygons
    }
  }, (err, task) => {
      // do something with task
  });
});
```

```python
from flask import request
import scaleapi

client = scaleapi.ScaleClient('{{ApiKey}}')

# This example uses Flask
@app.route('/polygon_task_callback_handler', methods=['POST'])
def create_annotation_task():
  # Validate callback auth key
  ...

  polygons = request.json['response']['annotations']
  attachment = request.json['task']['params']['attachment']

  task = client.create_annotation_task(
      callback_url='http://www.example.com/annotation_task_callback_handler',
      instruction='Draw a box around each **car** and **pedestrian**',
      attachment_type='image',
      attachment=attachment,
      objects_to_annotate=['car', 'pedestrian'],
      with_labels=True,
      min_width='30',
      min_height='30',
      layers={'polygons': polygons}
  )

  # do something with the task
```

```ruby
require 'scale'

class ExampleController < ActionController::Base
  def initialize
    @scale = Scale.new(api_key: '{{ApiKey}}')
  end

  # This example uses Rails, and assumes you map this to a POST route
  def polygon_task_callback_handler
    # Validate callback auth key
    ...

    polygons = params['response']['annotations']
    attachment = params['task']['params']['attachment']

    task = @scale.create_annotation_task({
      callback_url: 'http://www.example.com/annotation_task_callback_handler',
      instruction: 'Draw a box around each **car** and **pedestrian**',
      attachment_type: 'image',
      attachment: attachment,
      objects_to_annotate: ['car', 'pedestrian'],
      with_labels: true,
      min_width: '30',
      min_height: '30',
      layers: {polygons: polygons}
    })

    # do something with the task
  end
end
```

“Layers” can be used to specify existing (read-only) boxes, lines, polygons, and/or cuboids to be pre-drawn on an image.

For instance, you could specify boxes around the cars of an image, for a task that requires drawing polygons around the currently boxed cars. Or you could create a task for drawing boxes around all cars which you hadn't already recognized.

To specify layers, you can pass an optional `layers` parameter in the request for `annotation`, `lineannotation`, `polygonannotation`, or `pointannotation` tasks. They can also be used in `categorization` tasks if the `attachment_type` is `image`.

The `layers` parameter can contains fields for `boxes`, `lines`, `polygons`, and `cuboids`, which are arrays of the corresponding elements. Each of these elements are specified in the same format as the responses for their respective endpoints.

## Boxes
> Example layers param with boxes

```json
{
    "lines": [
        ...
    ],
    "polygons": [
        ...
    ],
    "boxes": [
        {
            "label": "car",
            "height": 97,
            "width": 147,
            "top": 229,
            "left": 300
        }
    ],
    "cuboids": [
        ...
    ]
}
```

Each of the `boxes` is specified with an object containing `left`, `top`, `width`, and `height` keys, and an optional `label`.

## Polygons
> Example layers param with polygons

```json
{
    ...
    "polygons": [
        {
            "vertices": [
                {
                    "y": 145,
                    "x": 356
                },
                {
                    "y": 103,
                    "x": 502
                },
                {
                    "y": 264,
                    "x": 482
                }
            ],
            "label": "building"
        }
    ]
}
```

`polygons` are objects with an optional `label` field, and a `vertices` field which contains a list of objects with `x` and `y` attributes.

## Lines
> Example layers param with lines

```json
{
    ...
    "lines": [
        {
            "vertices": [
                {
                    "y": 323,
                    "x": 414
                },
                {
                    "y": 164,
                    "x": 616
                },
                {
                    "y": 334,
                    "x": 776
                }
            ],
            "label" : "crosswalk",
            "spline": true
        }
    ]
}
```

`lines` are objects with an optional `label` field, and a `vertices` field which contains a list of objects with `x` and `y` attributes, similar to polygons. Additionally, line objects have an optional `spline` flag, which determines whether the curve used is linear (if the value is `false` or the param is not passed) or cardinal (if the value is `true`).

## Cuboids

> Example layers param with cuboids

```json
{
    ...
    "cuboids": [
        {
            "vertices" : [
                {
                    "description" : "face-topleft",
                    "y" : 219.0,
                    "x" : 137.0
                },
                {
                    "description" : "face-bottomleft",
                    "y" : 318.0,
                    "x" : 137.0
                },
                {
                    "description" : "face-topright",
                    "y" : 219.0,
                    "x" : 245.0
                },
                {
                    "description" : "face-bottomright",
                    "y" : 318.0,
                    "x" : 245.0
                },
                {
                    "description" : "side-topcorner",
                    "y" : 165.0,
                    "x" : 316.0
                },
                {
                    "description" : "side-bottomcorner",
                    "y" : 264.0,
                    "x" : 316.0
                }
            ],
            "label" : "car"
        }
    ]
}
```

`cuboids` are described in a similar way as polygons or lines, but the `vertices` also need a `description`, using the following values to identify them:

- face-topleft
- face-bottomleft
- face-topright
- face-bottomright
- side-topcorner
- side-bottomcorner

# Create Image Annotation Tasks

## Bounding Box Annotation

```shell
curl "https://api.scaleapi.com/v1/task/annotation" \
  -u "{{ApiKey}}:" \
  -d callback_url="http://www.example.com/callback" \
  -d instruction="Draw a box around each **car** and **pedestrian**." \
  -d attachment_type=image \
  -d attachment="http://i.imgur.com/XOJbalC.jpg" \
  -d objects_to_annotate="car" \
  -d objects_to_annotate="pedestrian" \
  -d with_labels=true \
  -d min_width="30" \
  -d min_height="30"
```
```python
import scaleapi

client = scaleapi.ScaleClient('{{ApiKey}}')

client.create_annotation_task(
    callback_url='http://www.example.com/callback',
    instruction='Draw a box around each **car** and **pedestrian**',
    attachment_type='image',
    attachment='http://i.imgur.com/XOJbalC.jpg',
    objects_to_annotate=['car', 'pedestrian'],
    with_labels=True,
    min_width='30',
    min_height='30'
)
```

```javascript
var scaleapi = require('scaleapi');

var client = scaleapi.ScaleClient('{{ApiKey}}');

client.createAnnotationTask({
  'callback_url': 'http://www.example.com/callback',
  'instruction': 'Draw a box around each **car** and **pedestrian**',
  'attachment_type': 'image',
  'attachment': 'http://i.imgur.com/XOJbalC.jpg',
  'objects_to_annotate': ['car', 'pedestrian'],
  'with_labels': true,
  'min_width': '30',
  'min_height': '30'
}, (err, task) => {
    // do something with task
});
```

```ruby
require 'scale'
scale = Scale.new(api_key: '{{ApiKey}}')

scale.create_annotation_task({
  callback_url: 'http://www.example.com/callback',
  instruction: 'Draw a box around each **car** and **pedestrian**',
  attachment_type: 'image',
  attachment: 'http://i.imgur.com/XOJbalC.jpg',
  objects_to_annotate: ['car', 'pedestrian'],
  with_labels: true,
  min_width: '30',
  min_height: '30'
})
=> #<Scale::Api::Tasks::ImageRecognition:0x007fcc11092f10 @task_id="58a6363baa9d139b20a4252f", @type="annotation", @instruction="Draw a box around each **car** and **pedestrian**", @params={"with_labels"=>true, "objects_to_annotate"=>["car", "pedestrian"], "attachment_type"=>"image", "attachment"=>"http://i.imgur.com/v4cBreD.jpg"}, @urgency="day", @response=nil, @callback_url="http://www.example.com/callback", @created_at=2017-02-16 23:31:07 UTC, @status="pending", @completed_at=nil, @callback_succeeded_at=nil, @metadata={}>
```

> The above command returns an object structured like this:

```json
{
  "task_id": "5774cc78b01249ab09f089dd",
  "created_at": "2016-9-03T07:38:32.368Z",
  "callback_url": "http://www.example.com/callback",
  "type": "annotation",
  "status": "pending",
  "instruction": "Draw a box around each **car** and **pedestrian**",
  "urgency": "day",
  "params": {
    "with_labels": true,
    "min_width": 30,
    "min_height": 30,
    "objects_to_annotate": [
      "car",
      "pedestrian"
    ],
    "attachment_type": "image",
    "attachment": "http://i.imgur.com/XOJbalC.jpg"
  },
  "metadata": {}
}
```

This endpoint creates a `annotation` task. In this task, one of our Scalers view the given image and draw bounding boxes around the specified objects, returning the positions and sizes of these boxes.

The required parameters for this task are `callback_url`, `attachment`, and `objects_to_annotate`. The `callback_url` is the URL which will be POSTed on task completion, and is described in more detail in the [Callbacks section](#callbacks). The `attachment` is a URL to an image you'd like to be annotated.

`objects_to_annotate` is an array of strings describing the different types of objects you'd like annotated.

You can optionally provide additional [markdown-enabled](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) instructions via the `instruction` parameter.

You can also optionally set `with_labels` to `true`, which will have Scalers provide labels for each box specifying what type of object it is. The labels will be strings in the `objects_to_annotate` list.

It is recommended, but not required, for you to flesh out your Markdown instructions with many examples of tasks being done correctly and incorrectly.

You may also provide `min_width` and `min_height` parameters, which will tell Scalers to only annotate objects whose bounding boxes are of dimension at least `min_width` x `min_height`.

If successful, Scale will immediately return the generated task object, of which you should at least store the `task_id`.

### HTTP Request

`POST https://api.scaleapi.com/v1/task/annotation`

### Parameters

Parameter | Type | Description
--------- | ---- | -------
`callback_url` | string | The full url (including the scheme `http://` or `https://`) of the callback when the task is completed. See the [Callback section](#callbacks) for more details about callbacks.
`objects_to_annotate` | [string] | An array of strings describing which objects you'd like bounding boxes to be drawn around. Each string should be singular and self-descriptive (ex: "cat", "street sign", "potato"). You may include at most 6 objects.
`attachment` | string | A URL to the image you'd like to be annotated with bounding boxes.
`with_labels` (optional, default `false`) | boolean | Specifies whether you'd like labels for each bounding box in the response. Each label will be a member of the `objects_to_annotate` array.
`min_height` (optional) | integer, default 0 | The minimum height in pixels of the bounding boxes you'd like to be made.
`min_width` (optional) | integer, default 0 | The minimum width in pixels of the bounding boxes you'd like to be made.
`urgency` (optional, default `day`) | string | A string describing the urgency of the response. One of `immediate`, `day`, or `week`, where `immediate` is a six hour response time.
`instruction` (optional) | string | A markdown-enabled string explaining how to draw the bounding boxes. You can use [markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to show example images, give structure to your instructions, and more.
`attachment_type` (optional, default `image`) | string | Describes what type of file the attachment is. We currently only support `image` for the annotation endpoint.
`metadata` (optional, default `{}`) | object | A set of key/value pairs that you can attach to a task object. It can be useful for storing additional information about the task in a structured format.
`layers` (optional) | object | A set of existing read-only objects to be pre-drawn on the image. See the <a href="#image-annotation-layers">Layers section</a> for more detail.

### Callback Format

> Example callback body sent on completion

```json
{
  "response": {
    "annotations": [
      {
        "left": 123,
        "top": 10,
        "width": 121,
        "height": 39,
        "label": "car"
      },
      {
        "left": 82,
        "top": 56,
        "width": 64,
        "height": 30,
        "label": "pedestrian"
      },
      { ... },
      { ... }
    ]
  },
  "task_id": "5774cc78b01249ab09f089dd",
  "task": {
    // populated task for convenience
    ...
  }
}
```

The `response` object, which is part of the callback POST request and permanently stored as part of the task object, will have either an `error` field or an `annotations` field.

If the annotation was completed successfully, the `annotations` field will contain an array of annotations. Each annotation will have the following values:

* `left`: The distance, in pixels, between the left border of the bounding box and the left border of the image.
* `top`: The distance, in pixels, between the top border of the bounding box and the top border of the image.
* `width`: The width, in pixels, of the bounding box.
* `height`: The height, in pixels, of the bounding box.
* `label` (if specified `with_labels` as `true`): The label for the bounding box, which will be one of the specified `task.params.objects_to_annotate`.

If the attachment was invalid, the error will be detailed in the `error` field.

<aside class="notice">
See the <a href="#callbacks">Callback section</a> for more details about callbacks.
</aside>

## Point Annotation

```shell
curl "https://api.scaleapi.com/v1/task/pointannotation" \
  -u "{{ApiKey}}:" \
  -d callback_url="http://www.example.com/callback" \
  -d instruction="Draw a point on every **headlight** and **brakelight** of a car in the image." \
  -d attachment_type=image \
  -d attachment="http://i.imgur.com/XOJbalC.jpg" \
  -d objects_to_annotate="headlight" \
  -d objects_to_annotate="brakelight" \
  -d with_labels=true
```
```python
import scaleapi

client = scaleapi.ScaleClient('{{ApiKey}}')

client.create_pointannotation_task(
    callback_url='http://www.example.com/callback',
    instruction='Draw a point on every **headlight** and **brakelight** of a car in the image.',
    attachment_type='image',
    attachment='http://i.imgur.com/XOJbalC.jpg',
    objects_to_annotate=['headlight', 'brakelight'],
    with_labels=True
)
```

```javascript
var scaleapi = require('scaleapi');

var client = scaleapi.ScaleClient('{{ApiKey}}');

client.createPointannotationTask({
  'callback_url': 'http://www.example.com/callback',
  'instruction': 'Draw a point on every **headlight** and **brakelight** of a car in the image.',
  'attachment_type': 'image',
  'attachment': 'http://i.imgur.com/XOJbalC.jpg',
  'objects_to_annotate': ['headlight', 'brakelight'],
  'with_labels': true
}, (err, task) => {
    // do something with task
});
```

```ruby
require 'scale'
scale = Scale.new(api_key: '{{ApiKey}}')

scale.create_pointannotation_task({
  callback_url: 'http://www.example.com/callback',
  instruction: 'Draw a point on every **headlight** and **brakelight** of a car in the image.',
  attachment_type: 'image',
  attachment: 'http://i.imgur.com/XOJbalC.jpg',
  objects_to_annotate: ['headlight', 'brakelight'],
  with_labels: true
})
=> #<Scale::Api::Tasks::Pointannotation:0x007fcc11092f10 @task_id="58a6363baa9d139b20a4252f", @type="pointannotation", @instruction="Draw a point on every **headlight** and **brakelight** of a car in the image.", @params={"with_labels"=>true, "objects_to_annotate"=>["headlight", "brakelight"], "attachment_type"=>"image", "attachment"=>"http://i.imgur.com/XOJbalC.jpg"}, @urgency="day", @response=nil, @callback_url="http://www.example.com/callback", @created_at=2017-02-16 23:31:07 UTC, @status="pending", @completed_at=nil, @callback_succeeded_at=nil, @metadata={}>
```

> The above command returns an object structured like this:

```json
{
  "task_id": "5774cc78b01249ab09f089dd",
  "created_at": "2016-9-03T07:38:32.368Z",
  "callback_url": "http://www.example.com/callback",
  "type": "pointannotation",
  "status": "pending",
  "instruction": "Draw a point on every **headlight** and **brakelight** of a car in the image.",
  "urgency": "day",
  "params": {
    "with_labels": true,
    "objects_to_annotate": [
      "headlight",
      "brakelight"
    ],
    "attachment_type": "image",
    "attachment": "http://i.imgur.com/XOJbalC.jpg"
  },
  "metadata": {}
}
```

This endpoint creates a `pointannotation` task. In this task, one of our Scalers view the given image and draw points at the specified locations, returning the locations of these points.

The required parameters for this task are `callback_url`, `attachment`, and `objects_to_annotate`. The `callback_url` is the URL which will be POSTed on task completion, and is described in more detail in the [Callbacks section](https://docs.scaleapi.com/#callbacks). The attachment is a URL to an image you’d like to be annotated.

`objects_to_annotate` is an array of strings describing the different types of objects you’d like annotated. You may include at most 6 objects in the `objects_to_annotate` parameter.

You can optionally provide additional [markdown-enabled](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) instructions via the `instruction` parameter.

You can also optionally set `with_labels` to true, which will have Scalers provide labels for each polygon specifying what type of object it is. The labels will belong to the `objects_to_annotate` list.

If successful, Scale will immediately return the generated task object, of which you should at least store the `task_id`.

### HTTP Request

`POST https://api.scaleapi.com/v1/task/pointannotation`

### Parameters

Parameter | Type | Description
--------- | ---- | -------
`callback_url` | string | The full url (including the scheme `http://` or `https://`) of the callback when the task is completed. See the [Callback section](#callbacks) for more details about callbacks.
`objects_to_annotate` | [string] | An array of strings describing which objects you’d like points to be drawn on. Each string should be singular and self-descriptive (ex: “cat”, “street sign”, “potato”). You may include at most 6 objects.
`attachment` | string | A URL to the image you’d like to be annotated with points.
`with_labels` (optional, default `false`) | boolean | Specifies whether you'd like labels for each bounding polygon in the response. Each label will be a member of the `objects_to_annotate` array.
`urgency` (optional, default `day`) | string | A string describing the urgency of the response. One of `immediate`, `day`, or `week`, where `immediate` is a 6 hour response time.
`instruction` (optional) | string | A markdown-enabled string explaining how to draw the points. You can use [markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to show example images, give structure to your instructions, and more.
`attachment_type` (optional, default `image`) | string | Describes what type of file the attachment is. We currently only support `image` for the polygon annotation endpoint.
`metadata` (optional, default `{}`) | object | A set of key/value pairs that you can attach to a task object. It can be useful for storing additional information about the task in a structured format.
`layers` (optional) | object | A set of existing read-only objects to be pre-drawn on the image. See the <a href="#image-annotation-layers">Layers section</a> for more detail.

### Callback Format

> Example callback body sent on completion

```json
{
  "response": {
    "annotations": [
      {
        "label": "headlight",
        "x": 123,
        "y": 10
      },
      {
        "label": "headlight",
        "x": 140,
        "y": 49
      },
      {
        "label": "brakelight",
        "x": 67,
        "y": 34
      }
    ]
  },
  "task_id": "5774cc78b01249ab09f089dd",
  "task": {
    // task inlined for convenience
    ...
  }
}
```

The `response` field, which is part of the callback POST request and permanently stored as part of the task object, will contain either an `annotations` field or an `error` field.

The `annotations` field will contain an array of point annotations. Each annotation will have the following values:

* `x`: The distance, in pixels, between the point and the left border of the image.
* `y`: The distance, in pixels, between the point and the top border of the image.
* `label` (if specified `with_labels` as `true`): The label for the point, which will be one of the specified `task.params.objects_to_annotate`.

If the attachment was invalid, the error will be detailed in the `error` field.

<aside class="notice">
See the <a href="#callbacks">Callback section</a> for more details about callbacks.
</aside>

## Line Annotation

```shell
curl "https://api.scaleapi.com/v1/task/lineannotation" \
  -u "{{ApiKey}}:" \
  -d callback_url="http://www.example.com/callback" \
  -d instruction="Annotate lines over all of the **lane lines** in the street-level image." \
  -d attachment_type=image \
  -d attachment="http://i.imgur.com/XOJbalC.jpg" \
  -d objects_to_annotate="solid line" \
  -d objects_to_annotate="dashed line" \
  -d with_labels=true
```
```python
import scaleapi

client = scaleapi.ScaleClient('{{ApiKey}}')

client.create_lineannotation_task(
    callback_url='http://www.example.com/callback',
    instruction='Annotate lines over all of the **lane lines** in the street-level image.',
    attachment_type='image',
    attachment='http://i.imgur.com/XOJbalC.jpg',
    objects_to_annotate=['solid line', 'dashed line'],
    with_labels=True
)
```

```javascript
var scaleapi = require('scaleapi');

var client = scaleapi.ScaleClient('{{ApiKey}}');

client.createLineannotationTask({
  'callback_url': 'http://www.example.com/callback',
  'instruction': 'Annotate lines over all of the **lane lines** in the street-level image.',
  'attachment_type': 'image',
  'attachment': 'http://i.imgur.com/XOJbalC.jpg',
  'objects_to_annotate': ['solid line', 'dashed line'],
  'with_labels': true
}, (err, task) => {
    // do something with task
});
```

```ruby
require 'scale'
scale = Scale.new(api_key: '{{ApiKey}}')

scale.create_lineannotation_task({
  callback_url: 'http://www.example.com/callback',
  instruction: 'Annotate lines over all of the **lane lines** in the street-level image.',
  attachment_type: 'image',
  attachment: 'http://i.imgur.com/XOJbalC.jpg',
  objects_to_annotate: ['solid line', 'dashed line'],
  with_labels: true
})
=> #<Scale::Api::Tasks::Lineannotation:0x007fcc11092f10 @task_id="58a6363baa9d139b20a4252f", @type="lineannotation", @instruction="Annotate lines over all of the **lane lines** in the street-level image.", @params={"with_labels"=>true, "objects_to_annotate"=>["solid line", "dashed line"], "attachment_type"=>"image", "attachment"=>"http://i.imgur.com/XOJbalC.jpg"}, @urgency="day", @response=nil, @callback_url="http://www.example.com/callback", @created_at=2017-02-16 23:31:07 UTC, @status="pending", @completed_at=nil, @metadata={}>
```

> The above command returns an object structured like this:

```json
{
  "task_id": "5774cc78b01249ab09f089dd",
  "created_at": "2016-9-03T07:38:32.368Z",
  "callback_url": "http://www.example.com/callback",
  "type": "lineannotation",
  "status": "pending",
  "instruction": "Annotate lines over all of the **lane lines** in the street-level image.",
  "urgency": "day",
  "params": {
    "with_labels": true,
    "objects_to_annotate": [
      "solid line",
      "dashed line"
    ],
    "attachment_type": "image",
    "attachment": "http://i.imgur.com/XOJbalC.jpg"
  },
  "metadata": {}
}
```

This endpoint creates a `lineannotation` task. In this task, one of our Scalers view the given image and draw segmented lines along each object, returning the vertices of these segmented lines.

The required parameters for this task are `callback_url`, `attachment`, and `objects_to_annotate`. The `callback_url` is the URL which will be POSTed on task completion, and is described in more detail in the [Callbacks section](https://docs.scaleapi.com/#callbacks). The attachment is a URL to an image you’d like to be annotated.

`objects_to_annotate` is an array of strings describing the different types of objects you’d like annotated.

You can optionally provide additional [markdown-enabled](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) instructions via the `instruction` parameter.

You can also optionally set `with_labels` to true, which will have Scalers provide labels for each segmented line specifying what type of object it is. The labels will belong to the `objects_to_annotate` list.

If you'd prefer splines as opposed to segmented lines, then you may specify the `splines` flag as true.

You can also optionally set `min_vertices` and/or `max_vertices` which specify the minimum and maximum number of vertices that you would want on a line. Note the range is inclusive of both bounds. For example, if `min_vertices` is 2 and `max_vertices` is 2, then Scale will only return line segments.

If successful, Scale will immediately return the generated task object, of which you should at least store the `task_id`.

### HTTP Request

`POST https://api.scaleapi.com/v1/task/lineannotation`

### Parameters

Parameter | Type | Description
--------- | ---- | -------
`callback_url` | string | The full url (including the scheme `http://` or `https://`) of the callback when the task is completed. See the [Callback section](#callbacks) for more details about callbacks.
`objects_to_annotate` | [string] | An array of strings describing which objects you’d like segmented lines to be drawn along. Each string should be singular and self-descriptive (ex: “lane line”, “crop line”). You may include at most 3 objects.
`attachment` | string | A URL to the image you'd like to be annotated with segmented lines.
`with_labels` (optional, default `false`) | boolean | Specifies whether you’d like labels for each segmented line in the response. Each label will be a member of the `objects_to_annotate` array.
`urgency` (optional, default `day`) | string | A string describing the urgency of the response. One of `immediate`, `day`, or `week`, where `immediate` is a 6 hour response time.
`instruction` (optional) | string | A markdown-enabled string explaining how to draw the segmented lines. You can use [markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to show example images, give structure to your instructions, and more.
`attachment_type` (optional, default `image`) | string | Describes what type of file the attachment is. We currently only support `image` for the line annotation endpoint.
`splines` (optional, default `false`) | boolean | Specifies whether or not you'd like your lines drawn as cardinal splines instead of segmented lines
`min_vertices` (optional, default 1) | number | An optional parameter defining the minimum number of vertices in a valid line annotation for your request.
`max_vertices` (optional, default `null`) | number | An optional parameter defining the maximum number of vertices in a valid line annotation for your request. Must be at least `min_vertices`.
`metadata` (optional, default `{}`) | object | A set of key/value pairs that you can attach to a task object. It can be useful for storing additional information about the task in a structured format.
`layers` (optional) | object | A set of existing read-only objects to be pre-drawn on the image. See the <a href="#image-annotation-layers">Layers section</a> for more detail.

### Callback Format

> Example callback body sent on completion

```json
{
  "response": {
    "annotations": [
      {
        "label": "solid line",
        "vertices": [
            {
                "x": 123,
                "y": 10
            },
            {
                "x": 140,
                "y": 49
            },
            {
                "x": 67,
                "y": 34
            }
        ]
      },
      { ... },
      { ... }
    ]
  },
  "task_id": "5774cc78b01249ab09f089dd",
  "task": {
    // populated task for convenience
    ...
  }
}
```

The `response` field, which is part of the callback POST request and permanently stored as part of the task object, will contain either an `annotations` field or an `error` field.

The `annotations` field will contain an array of annotations. Each annotation will have the following values:

* `vertices`: An array describing the vertices of the segmented line, listed in order from one end to another. Each vertex will be described by an object with the following structure:
    * `x`: The distance, in pixels, between the vertex and the left border of the image.
    * `y`: The distance, in pixels, between the vertex and the top border of the image.
* `label` (if specified `with_labels` as `true`): The label for the line, which will be one of the specified `task.params.objects_to_annotate`.

If the attachment was invalid, the error will be detailed in the `error` field.

<aside class="notice">
See the <a href="#callbacks">Callback section</a> for more details about callbacks.
</aside>

## Polygon Annotation

```shell
curl "https://api.scaleapi.com/v1/task/polygonannotation" \
  -u "{{ApiKey}}:" \
  -d callback_url="http://www.example.com/callback" \
  -d instruction="Draw a tight polygon around every **car** in the image." \
  -d attachment_type=image \
  -d attachment="http://i.imgur.com/XOJbalC.jpg" \
  -d objects_to_annotate="car" \
  -d objects_to_annotate="truck" \
  -d with_labels=true
```
```python
import scaleapi

client = scaleapi.ScaleClient('{{ApiKey}}')

client.create_polygonannotation_task(
    callback_url='http://www.example.com/callback',
    instruction='Draw a tight polygon around every **car** in the image.',
    attachment_type='image',
    attachment='http://i.imgur.com/XOJbalC.jpg',
    objects_to_annotate=['car', 'truck'],
    with_labels=True
)
```

```javascript
var scaleapi = require('scaleapi');

var client = scaleapi.ScaleClient('{{ApiKey}}');

client.createPolygonannotationTask({
  'callback_url': 'http://www.example.com/callback',
  'instruction': 'Draw a tight polygon around every **car** in the image.',
  'attachment_type': 'image',
  'attachment': 'http://i.imgur.com/XOJbalC.jpg',
  'objects_to_annotate': ['car', 'truck'],
  'with_labels': true
}, (err, task) => {
    // do something with task
});
```

```ruby
require 'scale'
scale = Scale.new(api_key: '{{ApiKey}}')

scale.create_polygonannotation_task({
  callback_url: 'http://www.example.com/callback',
  instruction: 'Draw a tight polygon around every **car** in the image.',
  attachment_type: 'image',
  attachment: 'http://i.imgur.com/XOJbalC.jpg',
  objects_to_annotate: ['car', 'truck'],
  with_labels: true
})
=> #<Scale::Api::Tasks::Polygonannotation:0x007fcc11092f10 @task_id="58a6363baa9d139b20a4252f", @type="polygonannotation", @instruction="Draw a tight polygon around every **car** in the image.", @params={"with_labels"=>true, "objects_to_annotate"=>["car", "truck"], "attachment_type"=>"image", "attachment"=>"http://i.imgur.com/XOJbalC.jpg"}, @urgency="day", @response=nil, @callback_url="http://www.example.com/callback", @created_at=2017-02-16 23:31:07 UTC, @status="pending", @completed_at=nil, @callback_succeeded_at=nil, @metadata={}>
```

> The above command returns an object structured like this:

```json
{
  "task_id": "5774cc78b01249ab09f089dd",
  "created_at": "2016-9-03T07:38:32.368Z",
  "callback_url": "http://www.example.com/callback",
  "type": "polygonannotation",
  "status": "pending",
  "instruction": "Draw a tight polygon around every **car** in the image.",
  "urgency": "day",
  "params": {
    "with_labels": true,
    "objects_to_annotate": [
      "car",
      "truck"
    ],
    "attachment_type": "image",
    "attachment": "http://i.imgur.com/XOJbalC.jpg"
  },
  "metadata": {}
}
```

This endpoint creates a `polygonannotation` task. In this task, one of our Scalers view the given image and draw bounding polygons around the specified objects, returning the vertices of these polygons.

The required parameters for this task are `callback_url`, `attachment`, and `objects_to_annotate`. The `callback_url` is the URL which will be POSTed on task completion, and is described in more detail in the [Callbacks section](https://docs.scaleapi.com/#callbacks). The attachment is a URL to an image you’d like to be annotated.

`objects_to_annotate` is an array of strings describing the different types of objects you’d like annotated.

You can optionally provide additional [markdown-enabled](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) instructions via the `instruction` parameter.

You can also optionally set `with_labels` to true, which will have Scalers provide labels for each polygon specifying what type of object it is. The labels will belong to the `objects_to_annotate` list.

You can also optionally set `min_vertices` and/or `max_vertices` which specify the minimum and maximum number of vertices that you'd like on a polygon. Note the range is inclusive of both bounds. For example, if `min_vertices` is 3 and `max_vertices` is 5, then Scale will only return triangles, quadrilaterals, and pentagons.

If successful, Scale will immediately return the generated task object, of which you should at least store the `task_id`.

### HTTP Request

`POST https://api.scaleapi.com/v1/task/polygonannotation`

### Parameters

Parameter | Type | Description
--------- | ---- | -------
`callback_url` | string | The full url (including the scheme `http://` or `https://`) of the callback when the task is completed. See the [Callback section](#callbacks) for more details about callbacks.
`objects_to_annotate` | [string] | An array of strings describing which objects you’d like bounding polygons to be drawn around. Each string should be singular and self-descriptive (ex: “cat”, “street sign”, “potato”). You may include at most 6 objects.
`attachment` | string | A URL to the image you’d like to be annotated with bounding polygons.
`with_labels` (optional, default `false`) | boolean | Specifies whether you'd like labels for each bounding polygon in the response. Each label will be a member of the `objects_to_annotate` array.
`urgency` (optional, default `day`) | string | A string describing the urgency of the response. One of `immediate`, `day`, or `week`, where `immediate` is a 6 hour response time.
`instruction` (optional) | string | A markdown-enabled string explaining how to draw the bounding polygons. You can use [markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to show example images, give structure to your instructions, and more.
`attachment_type` (optional, default `image`) | string | Describes what type of file the attachment is. We currently only support `image` for the polygon annotation endpoint.
`min_vertices` (optional, default 1) | number | An optional parameter defining the minimum number of vertices in a valid polygon annotation for your request.
`max_vertices` (optional, default `null`) | number | An optional parameter defining the maximum number of vertices in a valid polygon annotation for your request. Must be at least `min_vertices`.
`metadata` (optional, default `{}`) | object | A set of key/value pairs that you can attach to a task object. It can be useful for storing additional information about the task in a structured format.
`layers` (optional) | object | A set of existing read-only objects to be pre-drawn on the image. See the <a href="#image-annotation-layers">Layers section</a> for more detail.

### Callback Format

> Example callback body sent on completion

```json
{
  "response": {
    "annotations": [
      {
        "label": "car",
        "vertices": [
            {
                "x": 123,
                "y": 10
            },
            {
                "x": 140,
                "y": 49
            },
            {
                "x": 67,
                "y": 34
            }
        ]
      },
      { ... },
      { ... }
    ]
  },
  "task_id": "5774cc78b01249ab09f089dd",
  "task": {
    // task inlined for convenience
    ...
  }
}
```

The `response` field, which is part of the callback POST request and permanently stored as part of the task object, will contain either an `annotations` field or an `error` field.

The `annotations` field will contain an array of annotations. Each annotation will have the following values:

* `vertices`: An array describing the vertices of the polygon, listed in order from one end to another. Each vertex will be described by an object with the following structure:
    * `x`: The distance, in pixels, between the vertex and the left border of the image.
    * `y`: The distance, in pixels, between the vertex and the top border of the image.
* `label` (if specified `with_labels` as `true`): The label for the line, which will be one of the specified `task.params.objects_to_annotate`.

If the attachment was invalid, the error will be detailed in the `error` field.

<aside class="notice">
See the <a href="#callbacks">Callback section</a> for more details about callbacks.
</aside>

## Semantic Segmentation

```shell
curl "https://api.scaleapi.com/v1/task/segmentannotation" \
  -u "{{ApiKey}}:" \
  -d callback_url="http://www.example.com/callback" \
  -d instruction="Please segment the image using the given labels." \
  -d attachment_type=image \
  -d attachment="http://i.imgur.com/XOJbalC.jpg" \
  -d labels="vehicle" \
  -d labels="background" \
  -d labels="road" \
  -d labels="vegetation" \
  -d labels="lane marking" \
  -d allow_unlabeled=false
```
```python
import scaleapi

client = scaleapi.ScaleClient('{{ApiKey}}')

client.create_segmentannotation_task(
    callback_url='http://www.example.com/callback',
    instruction='Please segment the image using the given labels.',
    attachment_type='image',
    attachment='http://i.imgur.com/XOJbalC.jpg',
    labels=['vehicle', 'background', 'road', 'vegetation', 'lane marking'],
    allow_unlabeled=False
)
```

```javascript
var scaleapi = require('scaleapi');

var client = scaleapi.ScaleClient('{{ApiKey}}');

client.createSegmentannotationTask({
  callback_url: 'http://www.example.com/callback',
  instruction: 'Please segment the image using the given labels.',
  attachment_type: 'image',
  attachment: 'http://i.imgur.com/XOJbalC.jpg',
  labels: ['vehicle', 'background', 'road', 'vegetation', 'lane marking'],
  allow_unlabeled: false
}, (err, task) => {
    // do something with task
});
```

```ruby
require 'scale'
scale = Scale.new(api_key: '{{ApiKey}}')

scale.create_segmentannotation_task({
  callback_url: 'http://www.example.com/callback',
  instruction: 'Please segment the image using the given labels.',
  attachment_type: 'image',
  attachment: 'http://i.imgur.com/XOJbalC.jpg',
  labels: ['vehicle', 'background', 'road', 'vegetation', 'lane marking'],
  allow_unlabeled: false
})
=> #<Scale::Api::Tasks::Segmentannotation:0x007fcc11092f10 @task_id="58a6363baa9d139b20a4252f", @type="segmentannotation", @instruction="Please segment the image using the given labels.", @params={"allow_unlabeled"=>false, "objects_to_annotate"=>['vehicle', 'background', 'road', 'vegetation', 'lane marking'], "attachment_type"=>"image", "attachment"=>"http://i.imgur.com/XOJbalC.jpg"}, @urgency="day", @response=nil, @callback_url="http://www.example.com/callback", @created_at=2017-02-16 23:31:07 UTC, @status="pending", @completed_at=nil, @callback_succeeded_at=nil, @metadata={}>
```

> The above command returns an object structured like this:

```json
{
  "task_id": "5774cc78b01249ab09f089dd",
  "created_at": "2016-9-03T07:38:32.368Z",
  "callback_url": "http://www.example.com/callback",
  "type": "segmentannotation",
  "status": "pending",
  "instruction": "Please segment the image using the given labels.",
  "urgency": "day",
  "params": {
    "allow_unlabeled": false,
    "objects_to_annotate": [
      "vehicle",
      "background",
      "road",
      "vegetation",
      "lane marking"
    ],
    "attachment_type": "image",
    "attachment": "http://i.imgur.com/XOJbalC.jpg"
  },
  "metadata": {}
}
```

This endpoint creates a `segmentannotation` task. In this task, one of our Scalers view the given image and classify every pixel of the image according to the labels provided. You will get a full semantic, pixel-wise, dense segmentation of the image.

The required parameters for this task are `callback_url`, `attachment`, and `labels`. The `callback_url` is the URL which will be POSTed on task completion, and is described in more detail in the [Callbacks section](https://docs.scaleapi.com/#callbacks). The `attachment` is a URL to an image you’d like to be segmented.

`labels` is an array of strings describing the different types of objects you’d like to be used to segment the image.

You can optionally provide additional [markdown-enabled](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) instructions via the `instruction` parameter.

You can also optionally set `allow_unlabeled` to true, which will allow the existence of unlabeled pixels in the segmentation response - otherwise, all pixels in the image will be classified (in which case it's important that there are labels for everything in the image, to avoid misclassification).

The response you will receive will be a series of images where each pixel's value corresponds to the label, either via a numerical index or a color mapping. You will also get separate masks for each label for convenience.

If successful, Scale will immediately return the generated task object, of which you should at least store the `task_id`.


### HTTP Request

`POST https://api.scaleapi.com/v1/task/segmentannotation`

### Parameters

Parameter | Type | Description
--------- | ---- | -------
`callback_url` | string | The full url (including the scheme `http://` or `https://`) of the callback when the task is completed. See the [Callback section](#callbacks) for more details about callbacks.
`labels` | [string] | An array of strings describing the different types of objects you’d like to be used to segment the image. Each string should be singular and descriptive (ex: `car`, `background`, `pole`). You may include at most 50 objects.
`attachment` | string | A URL to the image you’d like to be segmented.
`allow_unlabeled` (optional, default `false`) | boolean | Specifies whether you'll allow unlabeled pixels in the segmentation. If left with the default value of `false`, all pixels in the image will be classified using the labels you provided.
`urgency` (optional, default `day`) | string | A string describing the urgency of the response. One of `immediate`, `day`, or `week`, where `immediate` is a 6 hour response time.
`instruction` (optional) | string | A markdown-enabled string explaining how carry out the semantic segmentation. You can use [markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to show example images, give structure to your instructions, and more.
`attachment_type` (optional, default `image`) | string | Describes what type of file the attachment is. We currently only support `image` for the semantic segmentation endpoint.
`metadata` (optional, default `{}`) | object | A set of key/value pairs that you can attach to a task object. It can be useful for storing additional information about the task in a structured format.

### Callback Format

> Example callback body sent on completion

```json
{
  "task": {
    // task inlined for convenience
    ...
  },
  "response": {
    "annotations": {
      "unlabeled": null,
      "labeled": {
        "lane marking": "https://scaleapi-attachments.s3.amazonaws.com/3f184900-6809-11e7-bb22-c346fd2b0658",
        "vehicle": "https://scaleapi-attachments.s3-ap-northeast-1.amazonaws.com/b7566ef0-8119-11e7-ac39-7d56f40a5f60",
        "road": "https://scaleapi-attachments.s3-ap-northeast-1.amazonaws.com/b756bd10-8119-11e7-ac39-7d56f40a5f60",
        "vegetation": "https://scaleapi-attachments.s3-ap-northeast-1.amazonaws.com/b756bd11-8119-11e7-ac39-7d56f40a5f60",
        "background": "https://scaleapi-attachments.s3-ap-northeast-1.amazonaws.com/b7573240-8119-11e7-ac39-7d56f40a5f60"
      },
      "combined": {
        "image": "https://scaleapi-attachments.s3-ap-northeast-1.amazonaws.com/b7573241-8119-11e7-ac39-7d56f40a5f60",
        "indexedImage": "https://scaleapi-attachments.s3-ap-northeast-1.amazonaws.com/ba9a9d70-8119-11e7-ac39-7d56f40a5f60"
      }
    },
    "labelMapping": {
      "lane marking": {
        "color": "#9e3fff",
        "index": 5
      },
      "vehicle": {
        "color": "#8000ff",
        "index": 4
      },
      "background": {
        "color": "#00ffff",
        "index": 3
      },
      "road": {
        "color": "#80ff00",
        "index": 2
      },
      "vegetation": {
        "color": "#ff0000",
        "index": 1
      }
    },
    "instances": {}
  },
  "task_id": "598e0da3e8068e06002d9407"
}
```

The `response` field, which is part of the callback POST request and permanently stored as part of the `task` object, will contain a `labelMapping` and an `annotations` field.

`labelMapping` is a dictionary where the keys are each label name, and the value is an object with the `index` and `color` used to represent each label in the response images.

`annotations` is an object that contains URLs of PNG images describing the segmentation result in different ways:

* `combined`: an object containing the URLs of two PNG images describing the segmentation response:
    * `image`: a 4-channel PNG image URL where each non-transparent colored pixel represents a pixel annotated with a given label, and each transparent pixel represents an unlabeled one. The `color` values in the `labelMapping` object are used.
    * `indexedImage`: a 1-channel PNG image URL where each positive integer value represents a pixel annotated with a given label, and each 0 value represents an unlabeled pixel. The `index` values in the `labelMapping` object are used.
* `labeled`: a dictionary where the keys are each label name, and the values are either:
    *  a 4-channel PNG image URL where each non-transparent colored pixel (using the label's `color`) represents a pixel annotated with that label in the segmentation response, or
    * `null`, if there is no pixel in the image annotated with that label in the segmentation response
* `unlabeled`:
    * a 4-channel PNG image URL where each non-transparent black (#000000) pixel represents a pixel left unlabeled in the segmentation response, or
    * `null`, if there is no pixel left unlabeled in the segmentation response

<aside class="notice">
See the <a href="#callbacks">Callback section</a> for more details about callbacks.
</aside>
